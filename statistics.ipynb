{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from vocab import Vocab\n",
    "from constants import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"text-decoration: underline\">Statistics</span>\n",
    "This is the file where statistics are calculated\n",
    "\n",
    "#### <u>Stat-1: Method to calculate % of visits that have higher than certain threshold % of \"[unk]\" tokens </u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def percentage_visits_with_high_unk(vocab: Vocab, threshold: float = 0.3, for_single_vsit: bool = False):\n",
    "    visit_record_key = [\"SUBJECT_ID\", \"HADM_ID\", \"ICD9_CODE\", \"ATC4\"]\n",
    "    visit = pd.read_pickle(os.path.join(GLOBAL_DATA_PATH, MULTI_VISIT_PKL))[visit_record_key[1:]]\n",
    "    if for_single_vsit is True:\n",
    "        visit = pd.read_pickle(os.path.join(GLOBAL_DATA_PATH, SINGLE_VISIT_PKL))[visit_record_key[1:]]\n",
    "    total = visit.shape[0]\n",
    "    def process(row):\n",
    "        icd: list[str] = row[\"ICD9_CODE\"]\n",
    "        unk = 0\n",
    "        for code in icd:\n",
    "            if vocab.word2idx.get(code) == None:\n",
    "                unk += 1\n",
    "        if unk/len(icd) > threshold:\n",
    "            print(row[\"HADM_ID\"])\n",
    "            return 1\n",
    "    temp = visit.apply(process, axis=1)\n",
    "    count: int = temp.loc[temp == 1].shape[0]\n",
    "    return count/total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <u>Stat-2: Method to calculate stats of Table 2 from Original paper </u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[table_2_stats] # of patients (Single-Visit) 29189\n",
      "[table_2_stats] avg. # of visits (Single-Visit) 1.0\n",
      "[table_2_stats] avg. # of dx per visit per patient (Single-Visit) 11.444276953646922\n",
      "[table_2_stats] avg. # of rx per visit per patient (Single-Visit) 21.20703004556511\n",
      "[table_2_stats] unique # of dx (Single-Visit) 6191\n",
      "[table_2_stats] unique # of drx (Single-Visit) 398\n",
      "\n",
      "\n",
      "[table_2_stats] # of patients (Multi-Visit) 5917\n",
      "[table_2_stats] avg. # of visits (Multi-Visit) 2.677539293560926\n",
      "[table_2_stats] avg. # of dx per visit per patient (Multi-Visit)(This includes the first visit dx as well) 14.217572429464116\n",
      "[table_2_stats] avg. # of rx per visit per patient (Multi-Visit)(This includes the first visit rx as well) 22.555071640472132\n",
      "[table_2_stats] unique # of dx (Multi-Visit) 4551\n",
      "[table_2_stats] unique # of rx (Multi-Visit) 385\n"
     ]
    }
   ],
   "source": [
    "def table_2_stats():\n",
    "    visit_record_key = [\"SUBJECT_ID\", \"HADM_ID\", \"ICD9_CODE\", \"ATC4\"]\n",
    "    single_visit = pd.read_pickle(os.path.join(GLOBAL_DATA_PATH, SINGLE_VISIT_PKL))\n",
    "    multi_visit_temporal = pd.read_pickle(os.path.join(GLOBAL_DATA_PATH, MULTI_VISIT_TEMPORAL_PKL))\n",
    "    multi_visit = pd.read_pickle(os.path.join(GLOBAL_DATA_PATH, MULTI_VISIT_PKL))\n",
    "\n",
    "    # Single visit stats\n",
    "    single_visit_sbj_count = single_visit[visit_record_key[0]].nunique()\n",
    "    print(\"[table_2_stats] # of patients (Single-Visit)\", single_visit_sbj_count)\n",
    "    total_visits = single_visit[visit_record_key[:2]].groupby(\"SUBJECT_ID\").count().sum().values[0]\n",
    "    print(\"[table_2_stats] avg. # of visits (Single-Visit)\", total_visits/single_visit_sbj_count)\n",
    "    total_dx = single_visit[visit_record_key[2]].apply(len).sum()\n",
    "    print(\"[table_2_stats] avg. # of dx per visit per patient (Single-Visit)\", total_dx/total_visits)\n",
    "    total_rx = single_visit[visit_record_key[3]].apply(len).sum()\n",
    "    print(\"[table_2_stats] avg. # of rx per visit per patient (Single-Visit)\", total_rx/total_visits)\n",
    "    unique_dx = len(set(code for ls in single_visit[visit_record_key[2]] for code in ls))\n",
    "    print(\"[table_2_stats] unique # of dx (Single-Visit)\", unique_dx) # 7k since we do not filter patient data\n",
    "    # we replace in training/eval less frequent DX with \"[UNK]\" && similar for RX\n",
    "    unique_rx = len(set(code for ls in single_visit[visit_record_key[3]] for code in ls))\n",
    "    print(\"[table_2_stats] unique # of drx (Single-Visit)\", unique_rx)\n",
    "\n",
    "    # Multiple visit stats\n",
    "    multi_visit_sbj_count = multi_visit_temporal[visit_record_key[0]].nunique()\n",
    "    print(\"\\n\\n[table_2_stats] # of patients (Multi-Visit)\", multi_visit_sbj_count)\n",
    "    total_multi_visits = (multi_visit_temporal.groupby(by=[\"SUBJECT_ID\"])[\"T_1\"].max() + 1).sum()\n",
    "    print(\"[table_2_stats] avg. # of visits (Multi-Visit)\", total_multi_visits/multi_visit_sbj_count)\n",
    "    def process_icd(row: pd.Series):\n",
    "        row[\"ICD9_LEN\"] = sum([len(ls) for ls in row[\"ICD9_CODE\"]])\n",
    "        return row\n",
    "    # this can be improved but not P1    \n",
    "    total_multi_dx = multi_visit_temporal.apply(process_icd, axis=1).groupby(\"SUBJECT_ID\")[\"ICD9_LEN\"].max().sum() \n",
    "    print(\"[table_2_stats] avg. # of dx per visit per patient (Multi-Visit)(This includes the first visit dx as well)\"\\\n",
    "        , total_multi_dx/total_multi_visits) # though it is fall as seen in paper but it is because we are including both \n",
    "    def process_atc(row: pd.Series):\n",
    "        row[\"ATC4_LEN\"] = sum([len(ls) for ls in row[\"ATC4\"]])\n",
    "        return row\n",
    "    # this can be improved but not P1    \n",
    "    total_multi_rx = multi_visit_temporal.apply(process_atc, axis=1).groupby(\"SUBJECT_ID\")[\"ATC4_LEN\"].max().sum() \n",
    "    print(\"[table_2_stats] avg. # of rx per visit per patient (Multi-Visit)(This includes the first visit rx as well)\"\\\n",
    "        , total_multi_rx/total_multi_visits) # though it is fall as seen in paper but it is because we are including both \n",
    "    unique_dx_multi = set()\n",
    "    def store_unique_icd(row: pd.Series):\n",
    "        unique_dx_multi.update(code for ls in row[\"ICD9_CODE\"] for code in ls)\n",
    "        return row\n",
    "    multi_visit_temporal.apply(store_unique_icd, axis=1) \n",
    "    print(\"[table_2_stats] unique # of dx (Multi-Visit)\", len(unique_dx_multi))\n",
    "    unique_rx_multi = set()\n",
    "    def store_unique_atc(row: pd.Series):\n",
    "        unique_rx_multi.update(code for ls in row[\"ATC4\"] for code in ls)\n",
    "        return row\n",
    "    multi_visit_temporal.apply(store_unique_atc, axis=1) \n",
    "    print(\"[table_2_stats] unique # of rx (Multi-Visit)\", len(unique_rx_multi))\n",
    "\n",
    "table_2_stats()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6a82d6eb3804a92444605d7a5aa99dc8a820299debc222bc81f709e34341d1d1"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('illi_MS_DS')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
